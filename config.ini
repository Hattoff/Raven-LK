[open_ai]
api_key=api_keys/key_openai.txt
# text-davinci-003
model=gpt-3.5-turbo-0301
input_engine=text-embedding-ada-002
max_token_input=4097
[pinecone]
api_key=api_keys/key_pinecone.txt
environment=us-east1-gcp
index=raven-mvp
[raven]
gpt_log_dir=gpt3_logs
nexus_dir=nexus
prompt_dir=summary_prompts
prompt_template=prompt_response.txt
notes_template=notes_response.txt
[wiki]
wiki_pages=wiki_pages
wiki_metadata=wiki_metadata
[memory_management]
# The maximum number of tokens per cache leaving room remaining for prompts, instructions, and responses
cache_token_limit=1000
# The number of backup files the memory manager will keep before it starts to delete old ones, -1 is infinite
max_backup_states=-1
memory_state_dir=memory_management/memory_states
# Memories of different depths will all go to this root folder
memory_stash_dir=memory_management/memory_stash
stash_folder_template=depth_%%i_stash
memory_prompts_dir=memory_management/memory_processing_prompts
memory_namespace_template=episodic_depth_%%i
[conversation_management]
conversation_management_dir=conversation_management
conversation_stash_dir=conversation_management/conversation_stash
conversation_prompt_stash_dir=conversation_management/prompt_stash